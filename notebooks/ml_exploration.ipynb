{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Exploration: Days 2-3 - Feature Engineering & Baseline Model\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "**Day 2 - Feature Engineering Prep:**\n",
    "- Feature extraction planning\n",
    "- Train/test split design\n",
    "- Helper similarity functions\n",
    "\n",
    "**Day 3 - Baseline Model Construction:**\n",
    "- Weighted popularity scoring\n",
    "- Global movie ranking\n",
    "- Top-N recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.spatial.distance import jaccard\n",
    "\n",
    "# Import our feature engineering module\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from feature_engineering import (\n",
    "    encode_genres_onehot,\n",
    "    vectorize_tags_tfidf,\n",
    "    create_year_features,\n",
    "    FeaturePipeline\n",
    ")\n",
    "\n",
    "# Import baseline model functions\n",
    "from baseline_model import (\n",
    "    compute_weighted_popularity_score,\n",
    "    compute_popularity_scores,\n",
    "    rank_movies_globally,\n",
    "    filter_by_minimum_votes,\n",
    "    get_top_n_recommendations,\n",
    "    get_personalized_top_n,\n",
    "    compute_rating_statistics,\n",
    "    merge_movie_with_stats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Feature Extraction Planning\n",
    "\n",
    "## Overview\n",
    "\n",
    "For our movie recommendation system, we will extract several types of features:\n",
    "\n",
    "### 1.1 Genre Features (Categorical → Binary)\n",
    "- **Source**: `genres` column (e.g., \"Action|Comedy|Drama\")\n",
    "- **Encoding**: One-hot (multi-label) encoding\n",
    "- **Rationale**: Genres are the primary content descriptor and form the basis of content-based filtering\n",
    "\n",
    "### 1.2 Tag Features (Text → Numeric)\n",
    "- **Source**: User-generated tags\n",
    "- **Encoding**: TF-IDF vectorization\n",
    "- **Rationale**: Tags capture nuanced aspects of movies that genres miss (e.g., \"twist ending\", \"dark humor\")\n",
    "\n",
    "### 1.3 Temporal Features\n",
    "- **Source**: Year extracted from movie title (e.g., \"Toy Story (1995)\")\n",
    "- **Derived Features**:\n",
    "  - Release year (numeric)\n",
    "  - Decade (categorical/numeric)\n",
    "- **Rationale**: User preferences often correlate with movie eras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Feature Extraction Strategy\n",
    "\n",
    "```\n",
    "Raw Data → Preprocessing → Feature Extraction → Feature Matrix\n",
    "\n",
    "movies.csv ─────┬───> Genre One-Hot ────────────┐\n",
    "                │                               │\n",
    "tags.csv ───────┴───> Tag TF-IDF ───────────────┼───> Combined Feature Matrix\n",
    "                │                               │\n",
    "movie titles ───┴───> Year/Decade Extraction ───┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Feature extraction plan demonstration\n",
    "\n",
    "# Sample data for demonstration\n",
    "sample_movies = pd.DataFrame({\n",
    "    'movieId': [1, 2, 3],\n",
    "    'title': ['Toy Story (1995)', 'Jumanji (1995)', 'Heat (1995)'],\n",
    "    'genres': ['Animation|Children|Comedy', 'Adventure|Children|Fantasy', 'Action|Crime|Thriller'],\n",
    "    'tags': ['pixar animated fun', 'jungle adventure board game', 'heist robbery deniro pacino']\n",
    "})\n",
    "\n",
    "print(\"Sample Movies Data:\")\n",
    "print(sample_movies)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate genre one-hot encoding\n",
    "genre_features, genre_encoder = encode_genres_onehot(sample_movies, 'genres')\n",
    "print(\"Genre One-Hot Encoding:\")\n",
    "print(genre_features)\n",
    "print(f\"\\nGenre classes: {genre_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate year extraction\n",
    "year_features = create_year_features(sample_movies, 'title')\n",
    "print(\"Year Features:\")\n",
    "print(year_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Train/Test Split Design\n",
    "\n",
    "## 2.1 Split Strategy Considerations\n",
    "\n",
    "For recommendation systems, we must carefully consider how to split data:\n",
    "\n",
    "### Random Split\n",
    "- **Use Case**: Standard evaluation of model performance\n",
    "- **Pros**: Simple, unbiased sample\n",
    "- **Cons**: May leak temporal patterns\n",
    "\n",
    "### Temporal Split\n",
    "- **Use Case**: Simulating real-world deployment\n",
    "- **Pros**: More realistic evaluation\n",
    "- **Cons**: May bias toward recent items\n",
    "\n",
    "### User-based Split\n",
    "- **Use Case**: Evaluating cold-start scenarios\n",
    "- **Pros**: Tests generalization to new users\n",
    "- **Cons**: Different user behavior patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split Configuration\n",
    "\n",
    "SPLIT_CONFIG = {\n",
    "    'test_size': 0.2,           # 20% for testing\n",
    "    'validation_size': 0.1,     # 10% for validation (from training)\n",
    "    'random_state': 42,         # For reproducibility\n",
    "    'stratify': True,           # Stratify by rating distribution\n",
    "}\n",
    "\n",
    "print(\"Split Configuration:\")\n",
    "for key, value in SPLIT_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_test_split(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.2,\n",
    "    val_size: float = 0.1,\n",
    "    random_state: int = 42,\n",
    "    stratify_column: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create train/validation/test splits for the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe to split\n",
    "    test_size : float\n",
    "        Proportion of data for test set\n",
    "    val_size : float\n",
    "        Proportion of training data for validation set\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    stratify_column : str, optional\n",
    "        Column to use for stratified splitting\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_df, val_df, test_df : tuple of DataFrames\n",
    "    \"\"\"\n",
    "    stratify = df[stratify_column] if stratify_column and stratify_column in df.columns else None\n",
    "    \n",
    "    # First split: separate test set\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify\n",
    "    )\n",
    "    \n",
    "    # Second split: separate validation from training\n",
    "    stratify_val = train_val_df[stratify_column] if stratify_column and stratify_column in df.columns else None\n",
    "    \n",
    "    # Adjust validation size relative to remaining data\n",
    "    val_size_adjusted = val_size / (1 - test_size)\n",
    "    \n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=val_size_adjusted,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_val\n",
    "    )\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_split(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp_column: str,\n",
    "    test_ratio: float = 0.2,\n",
    "    val_ratio: float = 0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Create train/validation/test splits based on timestamp.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe with timestamp column\n",
    "    timestamp_column : str\n",
    "        Name of the timestamp column\n",
    "    test_ratio : float\n",
    "        Proportion of most recent data for test set\n",
    "    val_ratio : float\n",
    "        Proportion of data for validation set\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    train_df, val_df, test_df : tuple of DataFrames\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(timestamp_column)\n",
    "    n = len(df_sorted)\n",
    "    \n",
    "    test_start_idx = int(n * (1 - test_ratio))\n",
    "    val_start_idx = int(n * (1 - test_ratio - val_ratio))\n",
    "    \n",
    "    train_df = df_sorted.iloc[:val_start_idx]\n",
    "    val_df = df_sorted.iloc[val_start_idx:test_start_idx]\n",
    "    test_df = df_sorted.iloc[test_start_idx:]\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate splits with sample data\n",
    "\n",
    "sample_ratings = pd.DataFrame({\n",
    "    'userId': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4],\n",
    "    'movieId': [1, 2, 3, 1, 2, 4, 2, 3, 4, 1],\n",
    "    'rating': [4.0, 3.5, 5.0, 4.5, 3.0, 4.0, 5.0, 4.5, 3.5, 4.0],\n",
    "    'timestamp': [1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009]\n",
    "})\n",
    "\n",
    "print(\"Sample Ratings Data:\")\n",
    "print(sample_ratings)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Random split\n",
    "train, val, test = create_train_val_test_split(sample_ratings, test_size=0.2, val_size=0.1)\n",
    "print(f\"\\nRandom Split Sizes: Train={len(train)}, Val={len(val)}, Test={len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Helper Similarity Functions\n",
    "\n",
    "## 3.1 Similarity Metrics Overview\n",
    "\n",
    "For content-based filtering, we need to compute similarity between items:\n",
    "\n",
    "| Metric | Best For | Range |\n",
    "|--------|----------|-------|\n",
    "| Cosine | Sparse vectors (TF-IDF) | [-1, 1] |\n",
    "| Jaccard | Binary features (genres) | [0, 1] |\n",
    "| Euclidean | Dense numeric features | [0, ∞) |\n",
    "| Pearson | Rating patterns | [-1, 1] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(feature_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise cosine similarity between all items.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature_matrix : np.ndarray\n",
    "        Matrix of shape (n_items, n_features)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    similarity_matrix : np.ndarray\n",
    "        Matrix of shape (n_items, n_items) with pairwise similarities\n",
    "    \"\"\"\n",
    "    return cosine_similarity(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(binary_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise Jaccard similarity for binary features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    binary_matrix : np.ndarray\n",
    "        Binary matrix of shape (n_items, n_features)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    similarity_matrix : np.ndarray\n",
    "        Matrix of shape (n_items, n_items) with pairwise Jaccard similarities\n",
    "    \"\"\"\n",
    "    n_items = binary_matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((n_items, n_items))\n",
    "    \n",
    "    for i in range(n_items):\n",
    "        for j in range(i, n_items):\n",
    "            # Jaccard = intersection / union\n",
    "            intersection = np.sum(np.logical_and(binary_matrix[i], binary_matrix[j]))\n",
    "            union = np.sum(np.logical_or(binary_matrix[i], binary_matrix[j]))\n",
    "            \n",
    "            if union == 0:\n",
    "                sim = 0.0\n",
    "            else:\n",
    "                sim = intersection / union\n",
    "            \n",
    "            similarity_matrix[i, j] = sim\n",
    "            similarity_matrix[j, i] = sim\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_similarity(\n",
    "    feature_matrix: np.ndarray,\n",
    "    normalize: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute similarity based on Euclidean distance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature_matrix : np.ndarray\n",
    "        Matrix of shape (n_items, n_features)\n",
    "    normalize : bool\n",
    "        If True, normalize distances to [0, 1] range and convert to similarity\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    similarity_matrix : np.ndarray\n",
    "        Matrix of shape (n_items, n_items) with pairwise similarities\n",
    "    \"\"\"\n",
    "    distances = euclidean_distances(feature_matrix)\n",
    "    \n",
    "    if normalize:\n",
    "        # Convert distance to similarity: sim = 1 / (1 + distance)\n",
    "        similarity_matrix = 1 / (1 + distances)\n",
    "    else:\n",
    "        similarity_matrix = -distances  # Negative distance as similarity\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_similar_items(\n",
    "    similarity_matrix: np.ndarray,\n",
    "    item_idx: int,\n",
    "    top_n: int = 10,\n",
    "    exclude_self: bool = True\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Get the top N most similar items to a given item.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    similarity_matrix : np.ndarray\n",
    "        Precomputed similarity matrix\n",
    "    item_idx : int\n",
    "        Index of the query item\n",
    "    top_n : int\n",
    "        Number of similar items to return\n",
    "    exclude_self : bool\n",
    "        Whether to exclude the item itself from results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    similar_items : list of tuples\n",
    "        List of (item_idx, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    similarities = similarity_matrix[item_idx]\n",
    "    \n",
    "    if exclude_self:\n",
    "        # Set self-similarity to -inf to exclude\n",
    "        similarities = similarities.copy()\n",
    "        similarities[item_idx] = -np.inf\n",
    "    \n",
    "    # Get indices of top N similar items\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "    \n",
    "    return [(idx, similarities[idx]) for idx in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_similarity(\n",
    "    feature_matrices: list,\n",
    "    weights: list,\n",
    "    similarity_fn=cosine_similarity\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute weighted combination of multiple similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature_matrices : list of np.ndarray\n",
    "        List of feature matrices (one per feature type)\n",
    "    weights : list of float\n",
    "        Weights for each feature type (should sum to 1)\n",
    "    similarity_fn : callable\n",
    "        Similarity function to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    combined_similarity : np.ndarray\n",
    "        Weighted combination of similarity matrices\n",
    "    \"\"\"\n",
    "    if len(feature_matrices) != len(weights):\n",
    "        raise ValueError(\"Number of matrices must match number of weights\")\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = np.array(weights) / np.sum(weights)\n",
    "    \n",
    "    combined_similarity = None\n",
    "    \n",
    "    for matrix, weight in zip(feature_matrices, weights):\n",
    "        sim_matrix = similarity_fn(matrix)\n",
    "        \n",
    "        if combined_similarity is None:\n",
    "            combined_similarity = weight * sim_matrix\n",
    "        else:\n",
    "            combined_similarity += weight * sim_matrix\n",
    "    \n",
    "    return combined_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate similarity computations\n",
    "\n",
    "# Use genre features from earlier\n",
    "print(\"Genre Features Matrix:\")\n",
    "print(genre_features.values)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = compute_cosine_similarity(genre_features.values)\n",
    "print(\"\\nCosine Similarity Matrix:\")\n",
    "print(np.round(cosine_sim, 3))\n",
    "\n",
    "# Compute Jaccard similarity\n",
    "jaccard_sim = compute_jaccard_similarity(genre_features.values)\n",
    "print(\"\\nJaccard Similarity Matrix:\")\n",
    "print(np.round(jaccard_sim, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar movies to Toy Story (index 0)\n",
    "print(\"Movies most similar to 'Toy Story':\")\n",
    "similar_to_toy_story = get_top_similar_items(cosine_sim, item_idx=0, top_n=2)\n",
    "\n",
    "for idx, score in similar_to_toy_story:\n",
    "    print(f\"  {sample_movies.iloc[idx]['title']}: similarity = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Baseline Model Construction (Day 3)\n",
    "\n",
    "## 4.1 Weighted Popularity Scoring\n",
    "\n",
    "The baseline model uses a **weighted popularity score** inspired by IMDB's weighted rating formula:\n",
    "\n",
    "$$\\text{Weighted Score} = \\frac{v}{v + m} \\cdot R + \\frac{m}{v + m} \\cdot C$$\n",
    "\n",
    "Where:\n",
    "- $v$ = number of votes (ratings) for the movie\n",
    "- $m$ = minimum votes required (threshold)\n",
    "- $R$ = average rating of the movie\n",
    "- $C$ = global mean rating across all movies\n",
    "\n",
    "This approach:\n",
    "- Penalizes movies with few ratings (prevents outliers)\n",
    "- Rewards movies with many ratings (more reliable)\n",
    "- Provides a smooth transition between low and high vote counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Demonstrate weighted popularity scoring\n",
    "\n",
    "# Sample movie data with rating statistics\n",
    "sample_movies_with_ratings = pd.DataFrame({\n",
    "    'movieId': [1, 2, 3, 4, 5],\n",
    "    'title': ['Movie A (High Rated, Many Reviews)', \n",
    "              'Movie B (High Rated, Few Reviews)',\n",
    "              'Movie C (Average Rated, Many Reviews)',\n",
    "              'Movie D (Low Rated, Few Reviews)',\n",
    "              'Movie E (Very High Rated, Few Reviews)'],\n",
    "    'genres': ['Action|Drama', 'Comedy', 'Action|Thriller', 'Horror', 'Drama|Romance'],\n",
    "    'avg_rating': [4.5, 4.8, 3.5, 2.0, 5.0],\n",
    "    'rating_count': [500, 5, 300, 10, 3]\n",
    "})\n",
    "\n",
    "print(\"Sample Movies with Rating Statistics:\")\n",
    "print(sample_movies_with_ratings[['title', 'avg_rating', 'rating_count']])\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global mean\n",
    "global_mean = sample_movies_with_ratings['avg_rating'].mean()\n",
    "print(f\"Global Mean Rating: {global_mean:.2f}\")\n",
    "print(\"\\nComparing individual scores:\")\n",
    "\n",
    "for idx, row in sample_movies_with_ratings.iterrows():\n",
    "    score = compute_weighted_popularity_score(\n",
    "        avg_rating=row['avg_rating'],\n",
    "        rating_count=row['rating_count'],\n",
    "        global_mean=global_mean,\n",
    "        min_votes=10\n",
    "    )\n",
    "    print(f\"  {row['title'][:40]:40s} | Avg: {row['avg_rating']:.1f} | Count: {row['rating_count']:3d} | Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch compute popularity scores for all movies\n",
    "scores = compute_popularity_scores(\n",
    "    sample_movies_with_ratings,\n",
    "    rating_column='avg_rating',\n",
    "    count_column='rating_count',\n",
    "    min_votes=10\n",
    ")\n",
    "\n",
    "print(\"Computed Popularity Scores:\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Global Movie Ranking\n",
    "\n",
    "Once we have popularity scores, we can rank movies globally to identify the most popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank movies globally by popularity score\n",
    "ranked_movies = rank_movies_globally(\n",
    "    sample_movies_with_ratings,\n",
    "    rating_column='avg_rating',\n",
    "    count_column='rating_count',\n",
    "    min_votes=10\n",
    ")\n",
    "\n",
    "print(\"Movies Ranked by Weighted Popularity Score:\")\n",
    "print(ranked_movies[['title', 'avg_rating', 'rating_count', 'popularity_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter movies by minimum vote threshold\n",
    "filtered_movies = filter_by_minimum_votes(\n",
    "    sample_movies_with_ratings,\n",
    "    count_column='rating_count',\n",
    "    min_votes=10\n",
    ")\n",
    "\n",
    "print(f\"Movies with >= 10 votes ({len(filtered_movies)} movies):\")\n",
    "print(filtered_movies[['title', 'rating_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Top-N Recommendations\n",
    "\n",
    "The baseline model provides two types of recommendations:\n",
    "\n",
    "1. **Global Top-N**: Best movies overall (non-personalized)\n",
    "2. **Personalized Top-N**: Best movies excluding those already watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a larger sample dataset for demonstration\n",
    "larger_sample = pd.DataFrame({\n",
    "    'movieId': range(1, 11),\n",
    "    'title': [\n",
    "        'The Shawshank Redemption (1994)', 'The Godfather (1972)',\n",
    "        'The Dark Knight (2008)', 'Pulp Fiction (1994)',\n",
    "        'Fight Club (1999)', 'Inception (2010)',\n",
    "        'The Matrix (1999)', 'Goodfellas (1990)',\n",
    "        'The Silence of the Lambs (1991)', 'Interstellar (2014)'\n",
    "    ],\n",
    "    'avg_rating': [4.9, 4.8, 4.7, 4.6, 4.5, 4.6, 4.5, 4.4, 4.3, 4.5],\n",
    "    'rating_count': [250, 180, 350, 200, 150, 300, 400, 100, 120, 280]\n",
    "})\n",
    "\n",
    "print(\"Larger Sample Dataset:\")\n",
    "print(larger_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get global top-5 recommendations\n",
    "top_5 = get_top_n_recommendations(\n",
    "    larger_sample,\n",
    "    n=5,\n",
    "    min_votes=50\n",
    ")\n",
    "\n",
    "print(\"Top 5 Movie Recommendations (Global):\")\n",
    "print(top_5[['title', 'popularity_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalized recommendations - exclude movies user has already watched\n",
    "user_watched_movies = [1, 3, 7]  # User has watched movies with these IDs\n",
    "\n",
    "personalized_recs = get_personalized_top_n(\n",
    "    larger_sample,\n",
    "    user_watched_ids=user_watched_movies,\n",
    "    n=5,\n",
    "    min_votes=50\n",
    ")\n",
    "\n",
    "print(f\"Personalized Top 5 (excluding watched movies: {user_watched_movies}):\")\n",
    "print(personalized_recs[['movieId', 'title', 'popularity_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Working with Real Rating Data\n",
    "\n",
    "In practice, we start with raw ratings and compute statistics before applying the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate raw ratings data\n",
    "raw_ratings = pd.DataFrame({\n",
    "    'userId': [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5,\n",
    "               6, 6, 7, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10],\n",
    "    'movieId': [1, 2, 3, 1, 2, 4, 1, 3, 5, 2, 3, 5, 1, 4, 5,\n",
    "                1, 2, 1, 3, 4, 2, 3, 1, 5, 1, 2, 3, 4],\n",
    "    'rating': [5.0, 4.0, 4.5, 4.5, 3.5, 4.0, 5.0, 4.0, 3.5, 4.0, 4.5, 4.0, 4.5, 3.0, 4.0,\n",
    "               5.0, 4.5, 4.0, 4.5, 3.5, 4.0, 4.0, 4.5, 3.5, 5.0, 4.0, 4.5, 3.5]\n",
    "})\n",
    "\n",
    "# Movie metadata\n",
    "movie_metadata = pd.DataFrame({\n",
    "    'movieId': [1, 2, 3, 4, 5],\n",
    "    'title': ['Movie Alpha', 'Movie Beta', 'Movie Gamma', 'Movie Delta', 'Movie Epsilon'],\n",
    "    'genres': ['Action', 'Comedy', 'Drama', 'Thriller', 'Romance']\n",
    "})\n",
    "\n",
    "print(\"Sample Ratings Data:\")\n",
    "print(f\"Total ratings: {len(raw_ratings)}\")\n",
    "print(f\"Unique users: {raw_ratings['userId'].nunique()}\")\n",
    "print(f\"Unique movies: {raw_ratings['movieId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rating statistics from raw data\n",
    "stats = compute_rating_statistics(\n",
    "    raw_ratings,\n",
    "    movie_id_column='movieId',\n",
    "    rating_column='rating'\n",
    ")\n",
    "\n",
    "print(\"Rating Statistics per Movie:\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge movie metadata with rating statistics\n",
    "movies_with_stats = merge_movie_with_stats(\n",
    "    movie_metadata,\n",
    "    stats,\n",
    "    movie_id_column='movieId'\n",
    ")\n",
    "\n",
    "print(\"Movies with Rating Statistics:\")\n",
    "print(movies_with_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get recommendations using the merged data\n",
    "final_recommendations = get_top_n_recommendations(\n",
    "    movies_with_stats,\n",
    "    n=5,\n",
    "    min_votes=3  # Lower threshold for small dataset\n",
    ")\n",
    "\n",
    "print(\"Final Top Recommendations:\")\n",
    "print(final_recommendations[['title', 'genres', 'avg_rating', 'rating_count', 'popularity_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Baseline Model Evaluation\n",
    "\n",
    "The weighted popularity baseline provides:\n",
    "\n",
    "**Strengths:**\n",
    "- Simple to implement and understand\n",
    "- Fast computation (O(n) for n movies)\n",
    "- No cold-start problem for new users\n",
    "- Works well for popular content discovery\n",
    "\n",
    "**Limitations:**\n",
    "- Not personalized (same recommendations for everyone)\n",
    "- Favors popular items (filter bubble risk)\n",
    "- Ignores user preferences and item features\n",
    "\n",
    "This baseline serves as a comparison point for more sophisticated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare effect of different weight factors\n",
    "print(\"Effect of Weight Factor on Scores:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test with different weight factors\n",
    "for wf in [0.25, 0.5, 1.0, 2.0]:\n",
    "    print(f\"\\nWeight Factor = {wf}:\")\n",
    "    ranked = rank_movies_globally(\n",
    "        movies_with_stats,\n",
    "        min_votes=3,\n",
    "        weight_factor=wf\n",
    "    )\n",
    "    for idx, row in ranked.head(3).iterrows():\n",
    "        print(f\"  {row['title']}: {row['popularity_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook covered Days 2-3 of ML exploration:\n",
    "\n",
    "**Day 2 - Feature Engineering:**\n",
    "1. **Feature Extraction Planning**: Defined approach for genre, tag, and temporal features\n",
    "2. **Train/Test Split Design**: Implemented random and temporal split strategies\n",
    "3. **Similarity Functions**: Created helpers for cosine, Jaccard, and Euclidean similarity\n",
    "\n",
    "**Day 3 - Baseline Model:**\n",
    "4. **Weighted Popularity Scoring**: Bayesian average for robust movie scoring\n",
    "5. **Global Movie Ranking**: Ordering movies by popularity\n",
    "6. **Top-N Recommendations**: Both global and personalized recommendation generation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- [ ] Load actual MovieLens data and apply feature extraction\n",
    "- [ ] Evaluate baseline model on real data\n",
    "- [ ] Build content-based recommendation models\n",
    "- [ ] Implement collaborative filtering approach\n",
    "- [ ] Compare model performance against baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of all helper functions available:\n",
    "\n",
    "print(\"Feature Engineering Functions:\")\n",
    "print(\"  - encode_genres_onehot(): One-hot encode movie genres\")\n",
    "print(\"  - vectorize_tags_tfidf(): TF-IDF vectorize movie tags\")\n",
    "print(\"  - create_year_features(): Extract year and decade from titles\")\n",
    "print(\"  - FeaturePipeline: Complete feature extraction pipeline\")\n",
    "print(\"\")\n",
    "print(\"Split Functions:\")\n",
    "print(\"  - create_train_val_test_split(): Random train/val/test split\")\n",
    "print(\"  - create_temporal_split(): Time-based train/val/test split\")\n",
    "print(\"\")\n",
    "print(\"Similarity Functions:\")\n",
    "print(\"  - compute_cosine_similarity(): Cosine similarity for sparse features\")\n",
    "print(\"  - compute_jaccard_similarity(): Jaccard similarity for binary features\")\n",
    "print(\"  - compute_euclidean_similarity(): Euclidean distance-based similarity\")\n",
    "print(\"  - get_top_similar_items(): Get top-N similar items\")\n",
    "print(\"  - compute_weighted_similarity(): Combine multiple similarity matrices\")\n",
    "print(\"\")\n",
    "print(\"Baseline Model Functions:\")\n",
    "print(\"  - compute_weighted_popularity_score(): Single movie weighted score\")\n",
    "print(\"  - compute_popularity_scores(): Batch compute scores for all movies\")\n",
    "print(\"  - rank_movies_globally(): Rank movies by popularity score\")\n",
    "print(\"  - filter_by_minimum_votes(): Filter movies by vote threshold\")\n",
    "print(\"  - get_top_n_recommendations(): Get top-N global recommendations\")\n",
    "print(\"  - get_personalized_top_n(): Get personalized top-N (excluding watched)\")\n",
    "print(\"  - compute_rating_statistics(): Compute avg_rating and count from ratings\")\n",
    "print(\"  - merge_movie_with_stats(): Merge movie metadata with rating stats\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
