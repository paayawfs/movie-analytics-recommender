{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: ML Exploration for Movie Recommender System\n",
    "\n",
    "This notebook explores the MovieLens dataset and sets up the foundation for building a movie recommendation system.\n",
    "\n",
    "## Contents\n",
    "1. Dataset Loading and Inspection\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing\n",
    "4. Initial Modeling Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Import our custom data inspection module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data_inspection import (\n",
    "    load_ratings, load_movies, load_tags,\n",
    "    print_dataset_summary, get_ratings_statistics,\n",
    "    get_movies_statistics, get_tags_statistics\n",
    ")\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading and Inspection\n",
    "\n",
    "We'll load the three main datasets from MovieLens:\n",
    "- **ratings.csv**: User ratings for movies\n",
    "- **movies.csv**: Movie information (title, genres)\n",
    "- **tags.csv**: User-generated tags for movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths (adjust as needed)\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "# Load datasets\n",
    "# Uncomment the lines below once data files are available\n",
    "# ratings = load_ratings(DATA_PATH + 'ratings.csv')\n",
    "# movies = load_movies(DATA_PATH + 'movies.csv')\n",
    "# tags = load_tags(DATA_PATH + 'tags.csv')\n",
    "\n",
    "print('Note: Uncomment the data loading lines once the MovieLens dataset is available.')\n",
    "print('Expected files: ratings.csv, movies.csv, tags.csv in the data/ directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Ratings Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ratings dataset\n",
    "# Uncomment once data is loaded\n",
    "# print_dataset_summary(ratings, 'Ratings')\n",
    "# ratings_stats = get_ratings_statistics(ratings)\n",
    "# print(f\"\\nRatings Statistics:\")\n",
    "# for key, value in ratings_stats.items():\n",
    "#     if key != 'rating_distribution':\n",
    "#         print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Movies Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect movies dataset\n",
    "# Uncomment once data is loaded\n",
    "# print_dataset_summary(movies, 'Movies')\n",
    "# movies_stats = get_movies_statistics(movies)\n",
    "# print(f\"\\nMovies Statistics:\")\n",
    "# for key, value in movies_stats.items():\n",
    "#     if key != 'genre_distribution':\n",
    "#         print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tags Dataset Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect tags dataset\n",
    "# Uncomment once data is loaded\n",
    "# print_dataset_summary(tags, 'Tags')\n",
    "# tags_stats = get_tags_statistics(tags)\n",
    "# print(f\"\\nTags Statistics:\")\n",
    "# for key, value in tags_stats.items():\n",
    "#     if key != 'top_10_tags':\n",
    "#         print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rating distribution\n",
    "# Uncomment once data is loaded\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# ratings['rating'].value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
    "# plt.title('Distribution of Movie Ratings')\n",
    "# plt.xlabel('Rating')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Genre Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize genre distribution\n",
    "# Uncomment once data is loaded\n",
    "# genres = movies['genres'].str.split('|').explode()\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# genres.value_counts().plot(kind='bar', color='steelblue')\n",
    "# plt.title('Distribution of Movie Genres')\n",
    "# plt.xlabel('Genre')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 User Activity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user activity\n",
    "# Uncomment once data is loaded\n",
    "# user_activity = ratings.groupby('userId').size()\n",
    "# print(f\"User Activity Statistics:\")\n",
    "# print(f\"  Min ratings per user: {user_activity.min()}\")\n",
    "# print(f\"  Max ratings per user: {user_activity.max()}\")\n",
    "# print(f\"  Mean ratings per user: {user_activity.mean():.2f}\")\n",
    "# print(f\"  Median ratings per user: {user_activity.median():.2f}\")\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(user_activity, bins=50, color='steelblue', edgecolor='black')\n",
    "# plt.title('Distribution of Ratings per User')\n",
    "# plt.xlabel('Number of Ratings')\n",
    "# plt.ylabel('Number of Users')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Movie Popularity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze movie popularity\n",
    "# Uncomment once data is loaded\n",
    "# movie_popularity = ratings.groupby('movieId').agg({\n",
    "#     'rating': ['count', 'mean']\n",
    "# }).reset_index()\n",
    "# movie_popularity.columns = ['movieId', 'rating_count', 'rating_mean']\n",
    "# movie_popularity = movie_popularity.merge(movies[['movieId', 'title']], on='movieId')\n",
    "\n",
    "# print(\"Top 10 Most Rated Movies:\")\n",
    "# print(movie_popularity.nlargest(10, 'rating_count')[['title', 'rating_count', 'rating_mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-item rating matrix\n",
    "# Uncomment once data is loaded\n",
    "# user_item_matrix = ratings.pivot_table(\n",
    "#     index='userId',\n",
    "#     columns='movieId',\n",
    "#     values='rating',\n",
    "#     fill_value=0\n",
    "# )\n",
    "# print(f\"User-Item Matrix Shape: {user_item_matrix.shape}\")\n",
    "# print(f\"Sparsity: {(1 - (ratings.shape[0] / (user_item_matrix.shape[0] * user_item_matrix.shape[1]))) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for modeling\n",
    "# Uncomment once data is loaded\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_data, test_data = train_test_split(\n",
    "#     ratings,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "# print(f\"Training set size: {len(train_data)}\")\n",
    "# print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial Modeling Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Baseline Model: Mean Rating Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model using mean ratings\n",
    "# Uncomment once data is loaded\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# global_mean = train_data['rating'].mean()\n",
    "# baseline_predictions = np.full(len(test_data), global_mean)\n",
    "\n",
    "# rmse = np.sqrt(mean_squared_error(test_data['rating'], baseline_predictions))\n",
    "# mae = mean_absolute_error(test_data['rating'], baseline_predictions)\n",
    "\n",
    "# print(f\"Baseline Model (Global Mean) Performance:\")\n",
    "# print(f\"  RMSE: {rmse:.4f}\")\n",
    "# print(f\"  MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 User-Based Mean Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-based mean predictor\n",
    "# Uncomment once data is loaded\n",
    "# user_means = train_data.groupby('userId')['rating'].mean()\n",
    "# user_predictions = test_data['userId'].map(user_means).fillna(global_mean)\n",
    "\n",
    "# rmse_user = np.sqrt(mean_squared_error(test_data['rating'], user_predictions))\n",
    "# mae_user = mean_absolute_error(test_data['rating'], user_predictions)\n",
    "\n",
    "# print(f\"User Mean Predictor Performance:\")\n",
    "# print(f\"  RMSE: {rmse_user:.4f}\")\n",
    "# print(f\"  MAE: {mae_user:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Item-Based Mean Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-based mean predictor\n",
    "# Uncomment once data is loaded\n",
    "# item_means = train_data.groupby('movieId')['rating'].mean()\n",
    "# item_predictions = test_data['movieId'].map(item_means).fillna(global_mean)\n",
    "\n",
    "# rmse_item = np.sqrt(mean_squared_error(test_data['rating'], item_predictions))\n",
    "# mae_item = mean_absolute_error(test_data['rating'], item_predictions)\n",
    "\n",
    "# print(f\"Item Mean Predictor Performance:\")\n",
    "# print(f\"  RMSE: {rmse_item:.4f}\")\n",
    "# print(f\"  MAE: {mae_item:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "After this initial exploration, the following steps are planned:\n",
    "\n",
    "1. **Collaborative Filtering**: Implement user-based and item-based collaborative filtering\n",
    "2. **Matrix Factorization**: Apply SVD and ALS for latent factor models\n",
    "3. **Deep Learning**: Explore neural collaborative filtering approaches\n",
    "4. **Hybrid Models**: Combine content-based and collaborative filtering\n",
    "5. **Evaluation**: Implement comprehensive evaluation metrics (NDCG, precision@k, recall@k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Day 1 ML Exploration Complete!\")\n",
    "print(\"Next: Add MovieLens dataset and run the analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
